{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb20cb7-f605-4b03-b478-883119de30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "import random\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebca37d8-4100-4b9f-8a4c-a3a1fa7f490f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4767789-2a5c-419c-90ff-03016682d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_num_to_label():\n",
    "    with open(\"IP102/ip102_v1.1/num_label_reduced.txt\") as f:\n",
    "        num_to_label = {}\n",
    "        for text in f.read().split(\"\\n\"):\n",
    "            n,l = text.split(' ',1);\n",
    "            num_to_label[n] = l.strip()\n",
    "\n",
    "    return num_to_label\n",
    "\n",
    "num_to_label = create_num_to_label()\n",
    "\n",
    "def create_name_to_num():\n",
    "    with open(\"IP102/ip102_v1.1/name_num_table.txt\") as f:\n",
    "        name_to_num = [] # class data\n",
    "        for l in f.read().split(\"\\n\"):\n",
    "            v = tuple(l.split())\n",
    "            if v:\n",
    "                if str(int(v[1])+1) in num_to_label.keys():\n",
    "                    v = [v[0],str(int(v[1])+1)] # to fit the format in num_to_label.txt\n",
    "                    name_to_num.append(v)\n",
    "    \n",
    "    return np.array(name_to_num)\n",
    "\n",
    "name_to_num = create_name_to_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51177d16-3113-4241-9fd3-73728a49a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3595\n"
     ]
    }
   ],
   "source": [
    "original_DA_num_to_label = {23:\"corn borer\", 52:\"blister beetle\"} # original num_to_label\n",
    "\n",
    "DA_label_to_num = {\"corn borer\":0, \"blister beetle\":1} # num_to_label for CGAN\n",
    "\n",
    "def assign_augment_img(name_to_num):\n",
    "    DA_path_to_num = []\n",
    "    src_directory = \"IP102/ip102_v1.1/images/\"\n",
    "    for name, num in zip(name_to_num[:, 0], name_to_num[:, 1]):\n",
    "        num = int(num)\n",
    "        if num in np.array(list(original_DA_num_to_label.keys())):\n",
    "            DA_path_to_num.append([src_directory + name, DA_label_to_num[original_DA_num_to_label[num]]])\n",
    "\n",
    "    return np.array(DA_path_to_num)\n",
    "\n",
    "\n",
    "DA_path_to_num = assign_augment_img(name_to_num)\n",
    "print(len(DA_path_to_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4096d1e0-4c3e-48e5-b91c-576415ef750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "img_size = 32 #32\n",
    "epoch_count = 5000\n",
    "noise_dim = 100 \n",
    "n_class = 2\n",
    "\n",
    "tags = list(DA_label_to_num.keys())\n",
    "\n",
    "# Sample data\n",
    "image_paths = DA_path_to_num[:,0]\n",
    "labels = DA_path_to_num[:,1]\n",
    "\n",
    "# Load images and labels\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for path, label in zip(image_paths, labels):\n",
    "    img = load_img(path, target_size=(img_size,img_size))\n",
    "    img_array = img_to_array(img)\n",
    "    X_train.append(img_array)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train).astype(\"float32\") / 255.0\n",
    "\n",
    "# Encode string labels into integers\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_train = (X_train - 127.5) / 127.5\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3c68122-2106-4bf6-a838-aceb1d8d6c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(128, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(128,), dtype=tf.int64, name=None))>\n",
      "-------images---------\n",
      "Data Amount: 3595\n",
      "Image Size : 32 x 32\n",
      "Channel    : 3\n",
      "Shape      : (3595, 32, 32, 3)\n",
      "-------labels---------\n",
      "Data Amount: 3595\n",
      "Shape      : (3595,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(\"-------images---------\")\n",
    "print(f\"Data Amount: {len(X_train)}\")\n",
    "print(f\"Image Size : {len(X_train[0])} x {len(X_train[0,0])}\")\n",
    "print(f\"Channel    : {len(X_train[0,0,0])}\")\n",
    "print(f\"Shape      : {X_train.shape}\")\n",
    "\n",
    "print(\"-------labels---------\")\n",
    "print(f\"Data Amount: {len(y_train)}\")\n",
    "print(f\"Shape      : {y_train.shape}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c6a6b-ddf3-4711-bc83-e6a80f76b715",
   "metadata": {},
   "source": [
    "### CGAN with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51017064-2781-4bea-9e76-78bcc66a0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real, fake): # real, contains labels predicted for real images. Similary fake.\n",
    "    real_loss = bce_loss(tf.ones_like(real), real) # loss for real image; small is better\n",
    "    fake_loss = bce_loss(tf.zeros_like(fake), fake)# loss for fake image; small is better\n",
    "    total_loss = real_loss + fake_loss # sum\n",
    "    return total_loss\n",
    "  \n",
    "def generator_loss(preds):\n",
    "    return bce_loss(tf.ones_like(preds), preds) # loss for fake image; big is better\n",
    "  \n",
    "d_optimizer=Adam(learning_rate=0.0002, beta_1 = 0.5) # beta_1 is decay rate for momentum, set to 3\n",
    "g_optimizer=Adam(learning_rate=0.0002, beta_1 = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cd88da-3361-4ba0-9fff-f8584ac4f89f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m     model = Model([in_lat, in_label], out_layer)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m g_model = \u001b[43mbuild_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m g_model.summary()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mbuild_generator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_generator\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     in_label = \u001b[43mtf\u001b[49m.keras.layers.Input(shape=(\u001b[32m1\u001b[39m,))\n\u001b[32m      4\u001b[39m     li = tf.keras.layers.Embedding(n_class, \u001b[32m50\u001b[39m)(in_label)\n\u001b[32m      6\u001b[39m     n_nodes = \u001b[32m1\u001b[39m * \u001b[32m8\u001b[39m * \u001b[32m8\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "def build_generator():\n",
    "    \n",
    "    in_label = tf.keras.layers.Input(shape=(1,))\n",
    "    li = tf.keras.layers.Embedding(n_class, 50)(in_label)\n",
    "\n",
    "    n_nodes = 1 * 8 * 8\n",
    "    li = tf.keras.layers.Dense(n_nodes)(li)\n",
    "    li = tf.keras.layers.Reshape((8, 8, 1))(li)\n",
    "    in_lat = tf.keras.layers.Input(shape=(noise_dim,))\n",
    "\n",
    "    n_nodes = 128 * 8 * 8\n",
    "    gen = tf.keras.layers.Dense(n_nodes)(in_lat)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = tf.keras.layers.Reshape((8, 8, 128))(gen)\n",
    "    merge = tf.keras.layers.Concatenate()([gen, li])\n",
    "\n",
    "    gen = tf.keras.layers.Conv2DTranspose(\n",
    "        128, (4, 4), strides=(2, 2), padding='same')(merge)  \n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "\n",
    "    gen = tf.keras.layers.Conv2DTranspose(\n",
    "        128, (4, 4), strides=(2, 2), padding='same')(gen)  \n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "\n",
    "    out_layer = tf.keras.layers.Conv2D(\n",
    "        3, (8, 8), activation='tanh', padding='same')(gen)  \n",
    "\n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "g_model = build_generator()\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af473f65-bf57-46ea-a082-dea4c5e4b17f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     31\u001b[39m   model = Model([in_image, in_label], out_layer)\n\u001b[32m     33\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m d_model = \u001b[43mbuild_discriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m d_model.summary()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mbuild_discriminator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_discriminator\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m   in_label = \u001b[43mtf\u001b[49m.keras.layers.Input(shape=(\u001b[32m1\u001b[39m,))\n\u001b[32m      6\u001b[39m   li = tf.keras.layers.Embedding(n_class, \u001b[32m50\u001b[39m)(in_label)\n\u001b[32m      8\u001b[39m   n_nodes = img_size * img_size \n",
      "\u001b[31mNameError\u001b[39m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "def build_discriminator():\n",
    "    \n",
    " \n",
    "  in_label = tf.keras.layers.Input(shape=(1,))\n",
    "  \n",
    "  li = tf.keras.layers.Embedding(n_class, 50)(in_label)\n",
    "  \n",
    "  n_nodes = img_size * img_size \n",
    "  li = tf.keras.layers.Dense(n_nodes)(li) \n",
    " \n",
    "  li = tf.keras.layers.Reshape((img_size, img_size, 1))(li) \n",
    "\n",
    "\n",
    "  \n",
    "  in_image = tf.keras.layers.Input(shape=(img_size, img_size, 3)) \n",
    "  \n",
    "  merge = tf.keras.layers.Concatenate()([in_image, li]) # concatenate label noise and image\n",
    "\n",
    "  fe = tf.keras.layers.Conv2D(batch_size, (3,3), strides=(2,2), padding='same')(merge) \n",
    "  fe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
    "  \n",
    "  fe = tf.keras.layers.Conv2D(batch_size, (3,3), strides=(2,2), padding='same')(fe) \n",
    "  fe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
    "  \n",
    "  fe = tf.keras.layers.Flatten()(fe) \n",
    "  \n",
    "  fe = tf.keras.layers.Dropout(0.4)(fe)\n",
    "  \n",
    "  out_layer = tf.keras.layers.Dense(1, activation='sigmoid')(fe)\n",
    "\n",
    "  model = Model([in_image, in_label], out_layer)\n",
    "      \n",
    "  return model\n",
    "\n",
    "\n",
    "d_model = build_discriminator()\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed5ed388-a917-4481-822a-6509c23bd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(dataset):\n",
    "   \n",
    "    real_images, real_labels = dataset\n",
    " \n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, noise_dim))\n",
    "    generated_images = g_model([random_latent_vectors, real_labels])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_fake = d_model([generated_images, real_labels])\n",
    "        pred_real = d_model([real_images, real_labels])\n",
    "        \n",
    "        d_loss = discriminator_loss(pred_real, pred_fake)\n",
    "      \n",
    "    grads = tape.gradient(d_loss, d_model.trainable_variables)\n",
    "   \n",
    "    d_optimizer.apply_gradients(zip(grads, d_model.trainable_variables))\n",
    "\n",
    "   \n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, noise_dim))\n",
    "   \n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_images = g_model([random_latent_vectors, real_labels])\n",
    "        predictions = d_model([fake_images, real_labels])\n",
    "        g_loss = generator_loss(predictions)\n",
    "    \n",
    "    grads = tape.gradient(g_loss, g_model.trainable_variables)\n",
    "    g_optimizer.apply_gradients(zip(grads, g_model.trainable_variables))\n",
    "    \n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32ee0027-2e00-47d5-ba32-dbc9d3394cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(num_samples, n_class, g_model):\n",
    "    fig, axes = plt.subplots(n_class,num_samples, figsize=(10,5)) \n",
    "    fig.tight_layout()\n",
    "\n",
    "    for l in np.arange(n_class):\n",
    "      random_noise = tf.random.normal(shape=(num_samples, noise_dim))\n",
    "      label = tf.ones(num_samples)*l\n",
    "      label = tf.constant([[l]] * num_samples, dtype=tf.int32) # make values integer to be fed into Embedding\n",
    "        \n",
    "      gen_imgs = g_model.predict([random_noise, label])\n",
    "      for j in range(gen_imgs.shape[0]):\n",
    "        img = image.array_to_img(gen_imgs[j], scale=True)\n",
    "        axes[l,j].imshow(img)\n",
    "        axes[l,j].yaxis.set_ticks([])\n",
    "        axes[l,j].xaxis.set_ticks([])\n",
    "\n",
    "        if j ==0:\n",
    "          axes[l,j].set_ylabel(tags[l])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f51045e-8d1c-4f88-b387-5a24e65ce877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(dataset, epochs=\u001b[43mepoch_count\u001b[49m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      4\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[33m'\u001b[39m, epochs)\n",
      "\u001b[31mNameError\u001b[39m: name 'epoch_count' is not defined"
     ]
    }
   ],
   "source": [
    "def train(dataset, epochs=epoch_count):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch: ', epochs)\n",
    "        d_loss_list = []\n",
    "        g_loss_list = []\n",
    "        q_loss_list = []\n",
    "        start = time.time()\n",
    "        \n",
    "        itern = 0\n",
    "        for image_batch in tqdm(dataset):\n",
    "            real_images, real_labels = image_batch\n",
    "            d_loss, g_loss = train_step(image_batch)\n",
    "            d_loss_list.append(d_loss)\n",
    "            g_loss_list.append(g_loss)\n",
    "            itern=itern+1\n",
    "                \n",
    "        show_samples(3, n_class, g_model)\n",
    "            \n",
    "        print (f'Epoch: {epoch} -- Generator Loss: {np.mean(g_loss_list)}, Discriminator Loss: {np.mean(d_loss_list)}\\n')\n",
    "        print (f'Took {time.time()-start} seconds. \\n\\n')\n",
    "        \n",
    "\n",
    "train(dataset, epochs=epoch_count)\n",
    "model.save(f\"GAN_result/{str(datetime.datetime.today())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45845b6a-0516-4c3a-9b32-bdee7c93f561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7ab33-f11c-4007-be28-290c2c46e199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
