{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243645e1-d287-4db6-b892-daecb4f5d29b",
   "metadata": {},
   "source": [
    "## Import and data split initiaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a18780f-c796-407a-b3d7-eb6bbe704535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 287\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "import random\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb950119-a33b-4165-9fca-77e001eace9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.3.134\n",
      "False\n",
      "/Users/ikutatouma/Desktop/PBL5/project\n"
     ]
    }
   ],
   "source": [
    "print(ultralytics.__version__)\n",
    "# '8.3.134'\n",
    "print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d7f10-4b0a-4610-8803-4f11b28dff0a",
   "metadata": {},
   "source": [
    "### Move splitted data back to the directory images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91ebab7a-0e48-4cc7-a8d0-a679fdfa14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_back_img():\n",
    "    for root, dirs, files in os.walk(\"./IP102/dataset\"):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.jpg'):\n",
    "                src_file_path = os.path.join(root, file)\n",
    "                dst_file_path = os.path.join(\"IP102/ip102_v1.1/images/\", file)\n",
    "                shutil.move(src_file_path, dst_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c68102d3-dbf9-49ac-85b7-680ce5156dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_back_flag = True # True => put data back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9051479f-2c47-449d-b5fe-d2c776fd109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if move_back_flag:\n",
    "    move_back_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3893c8-6388-45dd-95f3-38e1e3ae0e59",
   "metadata": {},
   "source": [
    "## Create a look-up dictionary for label number and class noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06f5d888-ef63-4608-b6cb-4fc3c93aeb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IP102/ip102_v1.1/num_label_reduced.txt\") as f:\n",
    "    num_to_label = {}\n",
    "    for text in f.read().split(\"\\n\"):\n",
    "        n,l = text.split(' ',1);\n",
    "        num_to_label[n] = l.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865367d-fedd-4e60-839a-a0cb62b2d54f",
   "metadata": {},
   "source": [
    "## Create empty classification directory to fit the YOLO dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31fda1cf-213e-459f-b6ac-c1f1591a5cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_flag = False # True => create now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66abfc3a-9327-4d23-b22b-a664eec39550",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_flag == True:\n",
    "    for label in num_to_label.values():\n",
    "        train_class_dir = 'IP102/dataset/train/' + label\n",
    "        val_class_dir = 'IP102/dataset/val/' + label\n",
    "        test_class_dir = 'IP102/dataset/test/' + label\n",
    "        os.mkdir(train_class_dir)\n",
    "        os.mkdir(val_class_dir)\n",
    "        os.mkdir(test_class_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1353b-4bd3-4d45-b561-93ad07be503e",
   "metadata": {},
   "source": [
    "### Make a table for converting from image to label number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24fa05c5-cdd1-49ad-a328-1cd24a0fda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"IP102/ip102_v1.1/name_num_table.txt\" has image name and label number\n",
    "image name   (e.g.  xxxxx.jpg)\n",
    "class number (e.g.          1)\n",
    "\n",
    "name_to_num[:,0] => image names\n",
    "name_to_num[:,1] => label numbers\n",
    "\"\"\"\n",
    "\n",
    "with open(\"IP102/ip102_v1.1/name_num_table.txt\") as f:\n",
    "    name_to_num = [] # class data\n",
    "    for l in f.read().split(\"\\n\"):\n",
    "        v = tuple(l.split())\n",
    "        if v:\n",
    "            if str(int(v[1])+1) in num_to_label.keys():\n",
    "                v = [v[0],str(int(v[1])+1)] # to fit the format in num_to_label.txt\n",
    "                name_to_num.append(v)\n",
    "\n",
    "name_to_num = np.array(name_to_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57f8afe-24b1-4c87-9217-b70a1a93a0ec",
   "metadata": {},
   "source": [
    "### Move image to train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f83fbb9b-4c40-41cc-ba54-859c2d3ab621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def move_img(train_val_test_pack):\n",
    "    src_directory = \"IP102/ip102_v1.1/images/\"\n",
    "    for split_type, name_num_dic in train_val_test_pack.items():\n",
    "        for name, num in zip(name_num_dic[\"name\"], name_num_dic[\"num\"]):\n",
    "            dst_directory = \"IP102/dataset/{:s}/{:s}\".format(split_type, num_to_label[num])\n",
    "            shutil.move(src_directory + name, dst_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e33876-72ea-4389-8115-171b6b42d505",
   "metadata": {},
   "source": [
    "## Parameter setup for k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69bd7e49-d2f2-47d1-8001-361c13968d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_demo_flag = False\n",
    "methods = ['down_sampling', 'stratified']\n",
    "method_selection = 'down_sampling'\n",
    "down_sampling_size = 5 # size for each train, val, and test set in each fold \n",
    "stratified_size = 1/10 # reduced ratio\n",
    "k = 5 # number of folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58d05c-97f8-4595-b5b4-1412945f674d",
   "metadata": {},
   "source": [
    "## Reducing data size for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e9edd01-9b1e-4852-97c6-9cbd606e6825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size\n",
      "Whole:  14645\n"
     ]
    }
   ],
   "source": [
    "print(\"data size\")\n",
    "print(\"Whole: \", len(name_to_num))\n",
    "if quick_demo_flag == True:\n",
    "    if method_selection == 'down_sampling':\n",
    "        # Downsampling method\n",
    "        grouped = defaultdict(list)\n",
    "        for name, num in zip(name_to_num[:,0],name_to_num[:,1]):\n",
    "            grouped[num].append(name)\n",
    "    \n",
    "        min_size = min(len(names) for names in grouped.values())\n",
    "        accept_min = np.floor(min_size/(3*k)) # \n",
    "    \n",
    "        if (down_sampling_size > accept_min):\n",
    "            print(\"down_sampling_size is bigger than accpetable size. Some classes cannot be distributed to train/val/test sets.\")\n",
    "            down_sampling_size = accept_min\n",
    "            print(\"down_sampling_size is set to the minimun: \".format(down_sampling_size))\n",
    "            \n",
    "        random.seed(42)\n",
    "        \n",
    "        reduced_dataset_name = []\n",
    "        reduced_dataset_num = []\n",
    "        for num, names in grouped.items():\n",
    "            reduced_dataset_name.extend(random.sample(names,down_sampling_size*3*k))\n",
    "            reduced_dataset_num.extend([num]*down_sampling_size*3*k)\n",
    "    \n",
    "        final_name_to_num = np.array(list(zip(reduced_dataset_name,reduced_dataset_num)))\n",
    "\n",
    "    elif method_selection == 'stratified':\n",
    "        _, name_reduced_data, _, num_reduced_data = train_test_split(name_to_num[:,0], \n",
    "                                                                    name_to_num[:,1], \n",
    "                                                                    stratify=name_to_num[:,1],\n",
    "                                                                    test_size=stratified_size,\n",
    "                                                                    random_state=43)\n",
    "        final_name_to_num = np.array(list(zip(name_reduced_data,num_reduced_data)))\n",
    "\n",
    "    print(\"Reduced : \", len(final_name_to_num))\n",
    "  \n",
    "else:\n",
    "    final_name_to_num = name_to_num.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c66da-d58b-43c0-92cd-ff8843110459",
   "metadata": {},
   "source": [
    "### plot classification imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c922e205-eda0-497d-a1c9-3be06782523d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot for whole data\n",
    "def plot_class_dist(final_name_to_num, num_train, num_val, num_test, num_to_label, fold_count, save_dir):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    num_list = {\n",
    "        \"Whole\":final_name_to_num[:,1],\n",
    "        \"Train\":num_train,\n",
    "        \"Val\":num_val,\n",
    "        \"Test\":num_test\n",
    "    }\n",
    "    \n",
    "    l = len(num_list)\n",
    "    fig, ax= plt.subplots(2,2, figsize=(18, 10))\n",
    "    \n",
    "    \n",
    "    for i, (set_type, num) in enumerate(num_list.items()):\n",
    "        dataset_count = Counter([num_to_label[single_num] for single_num in num])\n",
    "        dataset_count = sorted(dataset_count.items(), key=lambda item: item[1],reverse=True)\n",
    "        class_names, count_values = zip(*dataset_count)\n",
    "\n",
    "        print(class_names)\n",
    "    \n",
    "        x = np.floor(i/2).astype(int)\n",
    "        y = i%2\n",
    "    \n",
    "        b_text = 20\n",
    "        m_text = 20\n",
    "        s_text = 5\n",
    "        \n",
    "        ax[x][y].bar(class_names, count_values)\n",
    "        ax[x][y].set_title('{:s} Data on Fold {}'.format(set_type, fold_count), fontsize=b_text, fontweight='bold')\n",
    "        ax[x][y].set_xlabel('Class Name', fontsize=m_text)\n",
    "        ax[x][y].set_ylabel('Data Size', fontsize=m_text)\n",
    "        ax[x][y].xaxis.set_tick_params(rotation=90)\n",
    "    \n",
    "    \n",
    "        max_count = max(count_values)\n",
    "    \n",
    "        n = int(np.floor(np.log10(max_count)))\n",
    "        step = 10**n\n",
    "    \n",
    "        ax[x][y].yaxis.set_major_locator(ticker.MultipleLocator(step))\n",
    "        ax[x][y].set_xticklabels(ax[x][y].get_xticklabels(), fontsize=s_text)\n",
    "        ax[x][y].set_yticklabels(ax[x][y].get_yticklabels(), fontsize=m_text)\n",
    "    \n",
    "        # y_ticks = list(ax[x][y].get_yticks())\n",
    "        # max_count_float = float(max_count)\n",
    "        \n",
    "        # if not any(np.isclose(tick, max_count_float) for tick in y_ticks):\n",
    "        #     y_ticks.append(max_count_float)\n",
    "        #     y_ticks = sorted(y_ticks)\n",
    "            \n",
    "    \n",
    "        # if max_count not in y_ticks:\n",
    "        #     y_ticks.append(max_count)\n",
    "        #     y_ticks = sorted(y_ticks)\n",
    "        \n",
    "        # ax[x][y].set_yticks(y_ticks)\n",
    "        # ax[x][y].set_ylim(bottom =0)\n",
    "    \n",
    "        # labels = [str(int(tick)) if tick.is_integer() else f\"{tick:.1f}\" for tick in y_ticks]\n",
    "        # ax[x][y].set_yticklabels(labels, fontsize=m_text)\n",
    "        \n",
    "    \n",
    "        print(\"Number of Classes for {} Data: {}\".format(set_type, len(class_names) ))\n",
    "    \n",
    "    fig.tight_layout(pad=3.0)\n",
    "    fig.savefig('{}/class_dist_fold_{}.png'.format(save_dir, fold_count))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550531f-1e7d-4eb1-a609-53a77235512b",
   "metadata": {},
   "source": [
    "## YOLO training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13976f7d-bf74-4a5a-a1e5-6ee96cc5e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_classify(fold_count, save_dir):\n",
    "    model = YOLO(\"yolov8n-cls.pt\")\n",
    "    \n",
    "    # Train model\n",
    "    train_results = model.train(\n",
    "        data=os.path.join(os.getcwd(), \"IP102/dataset\"),\n",
    "        epochs=1,\n",
    "        imgsz=640,\n",
    "        device=\"cpu\")\n",
    "\n",
    "    \n",
    "    # Validate\n",
    "    metrics = model.val()\n",
    "    \n",
    "    # Path to test dataset\n",
    "    test_dir = os.path.join(os.getcwd(), \"IP102/dataset/test\")\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # Get class mapping\n",
    "    class_names = model.names\n",
    "    \n",
    "    # Loop through test set\n",
    "    for class_name in os.listdir(test_dir):\n",
    "        class_path = os.path.join(test_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "    \n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            results = model.predict(image_path, verbose=False)\n",
    "            pred_idx = results[0].probs.top1\n",
    "            pred_name = class_names[pred_idx]\n",
    "            y_true.append(class_name)\n",
    "            y_pred.append(pred_name)\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"\\nEvaluation on Test Set:\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "    fold_evaluation = {\"accuracy\": acc,\"precison\":precision, \"recall\": recall, \"f1-score\":f1}\n",
    "    keys = fold_evaluation.keys()\n",
    "    rows = list(fold_evaluation.values())\n",
    "    \n",
    "    with open(\"{}/evaluation_fold_{}.csv\".format(save_dir,fold_count), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(keys)\n",
    "        writer.writerows([rows])\n",
    "\n",
    "\n",
    "    with open(\"{}/yolov8_config.json\".format(save_dir), \"w\") as f:\n",
    "        json.dump(model.overrides, f, indent=4)\n",
    "\n",
    "    true_pred = {\"true\":y_true, \"pred\":y_pred}\n",
    "    return true_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46e771-ae65-4532-864c-7fa7ab428c67",
   "metadata": {},
   "source": [
    "## 5-fold cross validation by StratifiedKFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73b79c5a-5650-42a7-b988-bb22ae072a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-30 16:03:31.034038\n",
      "['23' '68' '102' ... '102' '68' '102']\n",
      "('Cicadellidae', 'Lycorma delicatula', 'blister beetle', 'corn borer')\n",
      "Number of Classes for Whole Data: 4\n",
      "('Cicadellidae', 'Lycorma delicatula', 'blister beetle', 'corn borer')\n",
      "Number of Classes for Train Data: 4\n",
      "('Cicadellidae', 'Lycorma delicatula', 'blister beetle', 'corn borer')\n",
      "Number of Classes for Val Data: 4\n",
      "('Cicadellidae', 'Lycorma delicatula', 'blister beetle', 'corn borer')\n",
      "Number of Classes for Test Data: 4\n",
      "New https://pypi.org/project/ultralytics/8.3.146 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.134 🚀 Python-3.12.10 torch-2.2.2 CPU (Intel Core(TM) i9-9880H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/ikutatouma/Desktop/PBL5/project/IP102/dataset, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train35, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/ikutatouma/Desktop/PBL5/project/PBL5/runs/classify/train35, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/train... found 8787 images in 4 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/val... found 2929 images in 4 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/test... found 2929 images in 4 classes ✅ \n",
      "Overriding model.yaml nc=1000 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,443,412 parameters, 1,443,412 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 64.0±40.2 MB/s, size: 32.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/train... 878\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train-val-test : 6-2-2\n",
    "move_back_img()\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "fold_counter = 0;\n",
    "\n",
    "all_y_true_pred = {\"true\":[], \"pred\":[]}\n",
    "\n",
    "time = str(datetime.datetime.today())\n",
    "save_dir = \"result/{}\".format(time)\n",
    "os.mkdir(save_dir)\n",
    "print(time)\n",
    "for train_index, test_index in skf.split(final_name_to_num[:,0], final_name_to_num[:,1].astype(int)):\n",
    "    fold_counter+=1\n",
    "    test_dataset = np.array([final_name_to_num[i] for i in test_index])\n",
    "    name_test, num_test = test_dataset[:,0], test_dataset[:,1]\n",
    "    \n",
    "    train_dataset = np.array([final_name_to_num[i] for i in train_index])\n",
    "    name_train, name_val, num_train, num_val = train_test_split(train_dataset[:,0], \n",
    "                                                                    train_dataset[:,1], \n",
    "                                                                    stratify=train_dataset[:,1],\n",
    "                                                                    test_size=0.25,\n",
    "                                                                    random_state=43)\n",
    "    train_val_test_pack = {\n",
    "        \"train\": {\"name\":name_train,\"num\":num_train},\n",
    "        \"val\":{\"name\":name_val,\"num\":num_val},\n",
    "        \"test\":{\"name\":name_test,\"num\":num_test}\n",
    "    }\n",
    "    \n",
    "    print(train_val_test_pack[\"train\"][\"num\"])\n",
    "\n",
    "    move_img(train_val_test_pack)\n",
    "    plot_class_dist(final_name_to_num, num_train, num_val, num_test, num_to_label, fold_counter, save_dir)\n",
    "    y_true_pred_dic = yolo_classify(fold_counter,save_dir)\n",
    "    all_y_true_pred[\"true\"].extend(y_true_pred_dic[\"true\"])\n",
    "    all_y_true_pred[\"pred\"].extend(y_true_pred_dic[\"pred\"])\n",
    "    move_back_img()\n",
    "\n",
    "\n",
    "acc = accuracy_score(all_y_true_pred[\"true\"], all_y_true_pred[\"pred\"])\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_y_true_pred[\"true\"], all_y_true_pred[\"pred\"], average='macro')\n",
    "\n",
    "print(\"\\nEvaluation on total {} folds:\".format(k))\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "total_evaluation = {\"accuracy\": acc, \"precison\":precision, \"recall\": recall, \"f1-score\":f1}\n",
    "\n",
    "keys = all_y_true_pred.keys()\n",
    "rows = zip(*all_y_true_pred.values())\n",
    "\n",
    "with open(\"{}/true_pred.csv\".format(save_dir), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keys)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "keys = total_evaluation.keys()\n",
    "rows = list(total_evaluation.values())\n",
    "\n",
    "with open(\"{}/total_evaluation.csv\".format(save_dir), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keys)\n",
    "    writer.writerows([rows])\n",
    "\n",
    "all_y_true_pred[\"true\"] = np.array(all_y_true_pred[\"true\"]).flatten()\n",
    "all_y_true_pred[\"pred\"] = np.array(all_y_true_pred[\"pred\"]).flatten()\n",
    "\n",
    "labels = list(num_to_label.values())\n",
    "\n",
    "cm = confusion_matrix(all_y_true_pred[\"true\"], all_y_true_pred[\"pred\"], labels=labels)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, xticklabels=labels, yticklabels=labels, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"{}/Confusion Matrix.png\".format(save_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
