{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243645e1-d287-4db6-b892-daecb4f5d29b",
   "metadata": {},
   "source": [
    "## Import and data split initiaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a18780f-c796-407a-b3d7-eb6bbe704535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "import random\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb950119-a33b-4165-9fca-77e001eace9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.3.134\n",
      "False\n",
      "/Users/ikutatouma/Desktop/PBL5/project\n"
     ]
    }
   ],
   "source": [
    "print(ultralytics.__version__)\n",
    "# '8.3.134'\n",
    "print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d7f10-4b0a-4610-8803-4f11b28dff0a",
   "metadata": {},
   "source": [
    "### Move splitted data back to the directory images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ebab7a-0e48-4cc7-a8d0-a679fdfa14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_back_img():\n",
    "    for root, dirs, files in os.walk(\"./IP102/dataset\"):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.jpg'):\n",
    "                src_file_path = os.path.join(root, file)\n",
    "                dst_file_path = os.path.join(\"IP102/ip102_v1.1/images/\", file)\n",
    "                shutil.move(src_file_path, dst_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68102d3-dbf9-49ac-85b7-680ce5156dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_back_flag = True # True => put data back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9051479f-2c47-449d-b5fe-d2c776fd109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 335\n"
     ]
    }
   ],
   "source": [
    "if move_back_flag:\n",
    "    move_back_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3893c8-6388-45dd-95f3-38e1e3ae0e59",
   "metadata": {},
   "source": [
    "## Create a look-up dictionary for label number and class noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f5d888-ef63-4608-b6cb-4fc3c93aeb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_num_to_label():\n",
    "    with open(\"IP102/ip102_v1.1/num_label_reduced.txt\") as f:\n",
    "        num_to_label = {}\n",
    "        for text in f.read().split(\"\\n\"):\n",
    "            n,l = text.split(' ',1);\n",
    "            num_to_label[n] = l.strip()\n",
    "\n",
    "    return num_to_label\n",
    "\n",
    "num_to_label = create_num_to_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865367d-fedd-4e60-839a-a0cb62b2d54f",
   "metadata": {},
   "source": [
    "## Create empty classification directory to fit the YOLO dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31fda1cf-213e-459f-b6ac-c1f1591a5cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_flag = False # True => create now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66abfc3a-9327-4d23-b22b-a664eec39550",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_flag == True:\n",
    "    for label in num_to_label.values():\n",
    "        train_class_dir = 'IP102/dataset/train/' + label\n",
    "        val_class_dir = 'IP102/dataset/val/' + label\n",
    "        test_class_dir = 'IP102/dataset/test/' + label\n",
    "        os.mkdir(train_class_dir)\n",
    "        os.mkdir(val_class_dir)\n",
    "        os.mkdir(test_class_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1353b-4bd3-4d45-b561-93ad07be503e",
   "metadata": {},
   "source": [
    "### Make a table for converting from image to label number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24fa05c5-cdd1-49ad-a328-1cd24a0fda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"IP102/ip102_v1.1/name_num_table.txt\" has image name and label number\n",
    "image name   (e.g.  xxxxx.jpg)\n",
    "class number (e.g.          1)\n",
    "\n",
    "name_to_num[:,0] => image names\n",
    "name_to_num[:,1] => label numbers\n",
    "\"\"\"\n",
    "def create_name_to_num():\n",
    "    with open(\"IP102/ip102_v1.1/name_num_table.txt\") as f:\n",
    "        name_to_num = [] # class data\n",
    "        for l in f.read().split(\"\\n\"):\n",
    "            v = tuple(l.split())\n",
    "            if v:\n",
    "                if str(int(v[1])+1) in num_to_label.keys():\n",
    "                    v = [v[0],str(int(v[1])+1)] # to fit the format in num_to_label.txt\n",
    "                    name_to_num.append(v)\n",
    "    \n",
    "    return np.array(name_to_num)\n",
    "\n",
    "name_to_num = create_name_to_num()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57f8afe-24b1-4c87-9217-b70a1a93a0ec",
   "metadata": {},
   "source": [
    "### Move image to train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83fbb9b-4c40-41cc-ba54-859c2d3ab621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def move_img(train_val_test_pack):\n",
    "    src_directory = \"IP102/ip102_v1.1/images/\"\n",
    "    for split_type, name_num_dic in train_val_test_pack.items():\n",
    "        for name, num in zip(name_num_dic[\"name\"], name_num_dic[\"num\"]):\n",
    "            dst_directory = \"IP102/dataset/{:s}/{:s}\".format(split_type, num_to_label[num])\n",
    "            shutil.move(src_directory + name, dst_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e33876-72ea-4389-8115-171b6b42d505",
   "metadata": {},
   "source": [
    "## Parameter setup for k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69bd7e49-d2f2-47d1-8001-361c13968d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_demo_flag = False\n",
    "methods = ['down_sampling', 'stratified']\n",
    "method_selection = 'down_sampling'\n",
    "down_sampling_size = 5 # size for each train, val, and test set in each fold \n",
    "stratified_size = 1/10 # reduced ratio\n",
    "k = 5 # number of folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58d05c-97f8-4595-b5b4-1412945f674d",
   "metadata": {},
   "source": [
    "## Reducing data size for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e9edd01-9b1e-4852-97c6-9cbd606e6825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size\n",
      "Whole:  14645\n"
     ]
    }
   ],
   "source": [
    "print(\"data size\")\n",
    "print(\"Whole: \", len(name_to_num))\n",
    "if quick_demo_flag == True:\n",
    "    if method_selection == 'down_sampling':\n",
    "        # Downsampling method\n",
    "        grouped = defaultdict(list)\n",
    "        for name, num in zip(name_to_num[:,0],name_to_num[:,1]):\n",
    "            grouped[num].append(name)\n",
    "    \n",
    "        min_size = min(len(names) for names in grouped.values())\n",
    "        accept_min = np.floor(min_size/(3*k)) # \n",
    "    \n",
    "        if (down_sampling_size > accept_min):\n",
    "            print(\"down_sampling_size is bigger than accpetable size. Some classes cannot be distributed to train/val/test sets.\")\n",
    "            down_sampling_size = accept_min\n",
    "            print(\"down_sampling_size is set to the minimun: \".format(down_sampling_size))\n",
    "            \n",
    "        random.seed(42)\n",
    "        \n",
    "        reduced_dataset_name = []\n",
    "        reduced_dataset_num = []\n",
    "        for num, names in grouped.items():\n",
    "            reduced_dataset_name.extend(random.sample(names,down_sampling_size*3*k))\n",
    "            reduced_dataset_num.extend([num]*down_sampling_size*3*k)\n",
    "    \n",
    "        final_name_to_num = np.array(list(zip(reduced_dataset_name,reduced_dataset_num)))\n",
    "\n",
    "    elif method_selection == 'stratified':\n",
    "        _, name_reduced_data, _, num_reduced_data = train_test_split(name_to_num[:,0], \n",
    "                                                                    name_to_num[:,1], \n",
    "                                                                    stratify=name_to_num[:,1],\n",
    "                                                                    test_size=stratified_size,\n",
    "                                                                    random_state=43)\n",
    "        final_name_to_num = np.array(list(zip(name_reduced_data,num_reduced_data)))\n",
    "\n",
    "    print(\"Reduced : \", len(final_name_to_num))\n",
    "  \n",
    "else:\n",
    "    final_name_to_num = name_to_num.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c66da-d58b-43c0-92cd-ff8843110459",
   "metadata": {},
   "source": [
    "### plot classification imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c922e205-eda0-497d-a1c9-3be06782523d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot for whole data\n",
    "def plot_class_dist(final_name_to_num, num_train, num_val, num_test, num_to_label, fold_count, save_dir):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    num_list = {\n",
    "        \"Whole\":final_name_to_num[:,1],\n",
    "        \"Train\":num_train,\n",
    "        \"Val\":num_val,\n",
    "        \"Test\":num_test\n",
    "    }\n",
    "    \n",
    "    l = len(num_list)\n",
    "    fig, ax= plt.subplots(2,2, figsize=(18, 10))\n",
    "    \n",
    "    \n",
    "    for i, (set_type, num) in enumerate(num_list.items()):\n",
    "        dataset_count = Counter([num_to_label[single_num] for single_num in num])\n",
    "        dataset_count = sorted(dataset_count.items(), key=lambda item: item[1],reverse=True)\n",
    "        class_names, count_values = zip(*dataset_count)\n",
    "\n",
    "        print(class_names)\n",
    "    \n",
    "        x = np.floor(i/2).astype(int)\n",
    "        y = i%2\n",
    "    \n",
    "        b_text = 20\n",
    "        m_text = 20\n",
    "        s_text = 5\n",
    "        \n",
    "        ax[x][y].bar(class_names, count_values)\n",
    "        ax[x][y].set_title('{:s} Data on Fold {}'.format(set_type, fold_count), fontsize=b_text, fontweight='bold')\n",
    "        ax[x][y].set_xlabel('Class Name', fontsize=m_text)\n",
    "        ax[x][y].set_ylabel('Data Size', fontsize=m_text)\n",
    "        ax[x][y].xaxis.set_tick_params(rotation=90)\n",
    "    \n",
    "    \n",
    "        max_count = max(count_values)\n",
    "    \n",
    "        n = int(np.floor(np.log10(max_count)))\n",
    "        step = 10**n\n",
    "    \n",
    "        ax[x][y].yaxis.set_major_locator(ticker.MultipleLocator(step))\n",
    "        ax[x][y].set_xticklabels(ax[x][y].get_xticklabels(), fontsize=s_text)\n",
    "        ax[x][y].set_yticklabels(ax[x][y].get_yticklabels(), fontsize=m_text)\n",
    "    \n",
    "        # y_ticks = list(ax[x][y].get_yticks())\n",
    "        # max_count_float = float(max_count)\n",
    "        \n",
    "        # if not any(np.isclose(tick, max_count_float) for tick in y_ticks):\n",
    "        #     y_ticks.append(max_count_float)\n",
    "        #     y_ticks = sorted(y_ticks)\n",
    "            \n",
    "    \n",
    "        # if max_count not in y_ticks:\n",
    "        #     y_ticks.append(max_count)\n",
    "        #     y_ticks = sorted(y_ticks)\n",
    "        \n",
    "        # ax[x][y].set_yticks(y_ticks)\n",
    "        # ax[x][y].set_ylim(bottom =0)\n",
    "    \n",
    "        # labels = [str(int(tick)) if tick.is_integer() else f\"{tick:.1f}\" for tick in y_ticks]\n",
    "        # ax[x][y].set_yticklabels(labels, fontsize=m_text)\n",
    "        \n",
    "    \n",
    "        print(\"Number of Classes for {} Data: {}\".format(set_type, len(class_names) ))\n",
    "    \n",
    "    fig.tight_layout(pad=3.0)\n",
    "    fig.savefig('{}/class_dist_fold_{}.png'.format(save_dir, fold_count))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550531f-1e7d-4eb1-a609-53a77235512b",
   "metadata": {},
   "source": [
    "## YOLO training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13976f7d-bf74-4a5a-a1e5-6ee96cc5e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_classify(fold_count, save_dir):\n",
    "    model = YOLO(\"yolov8n-cls.pt\")\n",
    "    \n",
    "    # Train model\n",
    "    train_results = model.train(\n",
    "        data=os.path.join(os.getcwd(), \"IP102/dataset\"),\n",
    "        epochs=1,\n",
    "        imgsz=640,\n",
    "        device=\"cpu\")\n",
    "\n",
    "    \n",
    "    # Validate\n",
    "    metrics = model.val()\n",
    "    \n",
    "    # Path to test dataset\n",
    "    test_dir = os.path.join(os.getcwd(), \"IP102/dataset/test\")\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # Get class mapping\n",
    "    class_names = model.names\n",
    "    \n",
    "    # Loop through test set\n",
    "    for class_name in os.listdir(test_dir):\n",
    "        class_path = os.path.join(test_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "    \n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            results = model.predict(image_path, verbose=False)\n",
    "            pred_idx = results[0].probs.top1\n",
    "            pred_name = class_names[pred_idx]\n",
    "            y_true.append(class_name)\n",
    "            y_pred.append(pred_name)\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"\\nEvaluation on Test Set:\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "    fold_evaluation = {\"accuracy\": acc,\"precison\":precision, \"recall\": recall, \"f1-score\":f1}\n",
    "    keys = fold_evaluation.keys()\n",
    "    rows = list(fold_evaluation.values())\n",
    "    \n",
    "    with open(\"{}/evaluation_fold_{}.csv\".format(save_dir,fold_count), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(keys)\n",
    "        writer.writerows([rows])\n",
    "\n",
    "\n",
    "    with open(\"{}/yolov8_config.json\".format(save_dir), \"w\") as f:\n",
    "        json.dump(model.overrides, f, indent=4)\n",
    "\n",
    "    true_pred = {\"true\":y_true, \"pred\":y_pred}\n",
    "    return true_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46e771-ae65-4532-864c-7fa7ab428c67",
   "metadata": {},
   "source": [
    "## 5-fold cross validation by StratifiedKFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73b79c5a-5650-42a7-b988-bb22ae072a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-12 13:13:58.196968\n",
      "['23' '68' '102' ... '102' '68' '102']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     23\u001b[39m train_val_test_pack = {\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m:name_train,\u001b[33m\"\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m\"\u001b[39m:num_train},\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m:{\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m:name_val,\u001b[33m\"\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m\"\u001b[39m:num_val},\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m:{\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m:name_test,\u001b[33m\"\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m\"\u001b[39m:num_test}\n\u001b[32m     27\u001b[39m }\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(train_val_test_pack[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mmove_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_val_test_pack\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m plot_class_dist(final_name_to_num, num_train, num_val, num_test, num_to_label, fold_counter, save_dir)\n\u001b[32m     33\u001b[39m y_true_pred_dic = yolo_classify(fold_counter,save_dir)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mmove_img\u001b[39m\u001b[34m(train_val_test_pack)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(name_num_dic[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m], name_num_dic[\u001b[33m\"\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m      5\u001b[39m     dst_directory = \u001b[33m\"\u001b[39m\u001b[33mIP102/dataset/\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m\"\u001b[39m.format(split_type, num_to_label[num])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_directory\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.10-macos-x86_64-none/lib/python3.12/shutil.py:847\u001b[39m, in \u001b[36mmove\u001b[39m\u001b[34m(src, dst, copy_function)\u001b[39m\n\u001b[32m    845\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[33m\"\u001b[39m\u001b[33mDestination path \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m already exists\u001b[39m\u001b[33m\"\u001b[39m % real_dst)\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m847\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.islink(src):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train-val-test : 6-2-2\n",
    "move_back_img()\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "fold_counter = 0;\n",
    "\n",
    "all_y_true_pred = {\"true\":[], \"pred\":[]}\n",
    "\n",
    "time = str(datetime.datetime.today())\n",
    "save_dir = \"result/{}\".format(time)\n",
    "os.mkdir(save_dir)\n",
    "print(time)\n",
    "for train_index, test_index in skf.split(final_name_to_num[:,0], final_name_to_num[:,1].astype(int)):\n",
    "    fold_counter+=1\n",
    "    test_dataset = np.array([final_name_to_num[i] for i in test_index])\n",
    "    name_test, num_test = test_dataset[:,0], test_dataset[:,1]\n",
    "    \n",
    "    train_dataset = np.array([final_name_to_num[i] for i in train_index])\n",
    "    name_train, name_val, num_train, num_val = train_test_split(train_dataset[:,0], \n",
    "                                                                    train_dataset[:,1], \n",
    "                                                                    stratify=train_dataset[:,1],\n",
    "                                                                    test_size=0.25,\n",
    "                                                                    random_state=43)\n",
    "    train_val_test_pack = {\n",
    "        \"train\": {\"name\":name_train,\"num\":num_train},\n",
    "        \"val\":{\"name\":name_val,\"num\":num_val},\n",
    "        \"test\":{\"name\":name_test,\"num\":num_test}\n",
    "    }\n",
    "    \n",
    "    print(train_val_test_pack[\"train\"][\"num\"])\n",
    "\n",
    "    move_img(train_val_test_pack)\n",
    "    plot_class_dist(final_name_to_num, num_train, num_val, num_test, num_to_label, fold_counter, save_dir)\n",
    "    y_true_pred_dic = yolo_classify(fold_counter,save_dir)\n",
    "    all_y_true_pred[\"true\"].extend(y_true_pred_dic[\"true\"])\n",
    "    all_y_true_pred[\"pred\"].extend(y_true_pred_dic[\"pred\"])\n",
    "    move_back_img()\n",
    "\n",
    "\n",
    "acc = accuracy_score(all_y_true_pred[\"true\"], all_y_true_pred[\"pred\"])\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_y_true_pred[\"true\"], all_y_true_pred[\"pred\"], average='macro')\n",
    "\n",
    "print(\"\\nEvaluation on total {} folds:\".format(k))\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "total_evaluation = {\"accuracy\": acc, \"precison\":precision, \"recall\": recall, \"f1-score\":f1}\n",
    "\n",
    "keys = all_y_true_pred.keys()\n",
    "rows = zip(*all_y_true_pred.values())\n",
    "\n",
    "with open(\"{}/true_pred.csv\".format(save_dir), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keys)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "keys = total_evaluation.keys()\n",
    "rows = list(total_evaluation.values())\n",
    "\n",
    "with open(\"{}/total_evaluation.csv\".format(save_dir), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keys)\n",
    "    writer.writerows([rows])\n",
    "\n",
    "all_y_true_pred[\"true\"] = np.array(all_y_true_pred[\"true\"]).flatten()\n",
    "all_y_true_pred[\"pred\"] = np.array(all_y_true_pred[\"pred\"]).flatten()\n",
    "\n",
    "labels = list(num_to_label.values())\n",
    "\n",
    "cm = confusion_matrix(all_y_true_pred[\"true\"], all_y_true_pred[\"pred\"], labels=labels)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, xticklabels=labels, yticklabels=labels, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"{}/Confusion Matrix.png\".format(save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61dda91-cd64-4205-83fb-cdb641d6d138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70399b-c011-420f-9d9c-fd98b16abcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
