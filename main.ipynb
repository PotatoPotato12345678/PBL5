{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243645e1-d287-4db6-b892-daecb4f5d29b",
   "metadata": {},
   "source": [
    "## Import and data split initiaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a18780f-c796-407a-b3d7-eb6bbe704535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "import random\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb950119-a33b-4165-9fca-77e001eace9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.3.134\n",
      "False\n",
      "/Users/ikutatouma/Desktop/PBL5/project\n"
     ]
    }
   ],
   "source": [
    "print(ultralytics.__version__)\n",
    "# '8.3.134'\n",
    "print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d7f10-4b0a-4610-8803-4f11b28dff0a",
   "metadata": {},
   "source": [
    "### Move splitted data back to the directory images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ebab7a-0e48-4cc7-a8d0-a679fdfa14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_back_img():\n",
    "    for root, dirs, files in os.walk(\"./IP102/dataset\"):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.jpg'):\n",
    "                src_file_path = os.path.join(root, file)\n",
    "                dst_file_path = os.path.join(\"IP102/ip102_v1.1/images/\", file)\n",
    "                shutil.move(src_file_path, dst_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68102d3-dbf9-49ac-85b7-680ce5156dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_back_flag = True # True => put data back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9051479f-2c47-449d-b5fe-d2c776fd109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if move_back_flag:\n",
    "    move_back_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3893c8-6388-45dd-95f3-38e1e3ae0e59",
   "metadata": {},
   "source": [
    "## Create a look-up dictionary for label number and class noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f5d888-ef63-4608-b6cb-4fc3c93aeb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IP102/ip102_v1.1/num_label_reduced.txt\") as f:\n",
    "    num_to_label = {}\n",
    "    for text in f.read().split(\"\\n\"):\n",
    "        n,l = text.split(' ',1);\n",
    "        num_to_label[n] = l.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865367d-fedd-4e60-839a-a0cb62b2d54f",
   "metadata": {},
   "source": [
    "## Create empty classification directory to fit the YOLO dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31fda1cf-213e-459f-b6ac-c1f1591a5cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_flag = False # True => create now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66abfc3a-9327-4d23-b22b-a664eec39550",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_flag == True:\n",
    "    for label in num_to_label.values():\n",
    "        train_class_dir = 'IP102/dataset/train/' + label\n",
    "        val_class_dir = 'IP102/dataset/val/' + label\n",
    "        test_class_dir = 'IP102/dataset/test/' + label\n",
    "        os.mkdir(train_class_dir)\n",
    "        os.mkdir(val_class_dir)\n",
    "        os.mkdir(test_class_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1353b-4bd3-4d45-b561-93ad07be503e",
   "metadata": {},
   "source": [
    "### Make a table for converting from image to label number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24fa05c5-cdd1-49ad-a328-1cd24a0fda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"IP102/ip102_v1.1/name_num_table.txt\" has image name and label number\n",
    "image name   (e.g.  xxxxx.jpg)\n",
    "class number (e.g.          1)\n",
    "\n",
    "name_to_num[:,0] => image names\n",
    "name_to_num[:,1] => label numbers\n",
    "\"\"\"\n",
    "\n",
    "with open(\"IP102/ip102_v1.1/name_num_table.txt\") as f:\n",
    "    name_to_num = [] # class data\n",
    "    for l in f.read().split(\"\\n\"):\n",
    "        v = tuple(l.split())\n",
    "        if v:\n",
    "            if str(int(v[1])+1) in num_to_label.keys():\n",
    "                v = [v[0],str(int(v[1])+1)] # to fit the format in num_to_label.txt\n",
    "                name_to_num.append(v)\n",
    "\n",
    "name_to_num = np.array(name_to_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57f8afe-24b1-4c87-9217-b70a1a93a0ec",
   "metadata": {},
   "source": [
    "### Move image to train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83fbb9b-4c40-41cc-ba54-859c2d3ab621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def move_img(train_val_test_pack):\n",
    "    src_directory = \"IP102/ip102_v1.1/images/\"\n",
    "    for split_type, name_num_dic in train_val_test_pack.items():\n",
    "        for name, num in zip(name_num_dic[\"name\"], name_num_dic[\"num\"]):\n",
    "            dst_directory = \"IP102/dataset/{:s}/{:s}\".format(split_type, num_to_label[num])\n",
    "            shutil.move(src_directory + name, dst_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e33876-72ea-4389-8115-171b6b42d505",
   "metadata": {},
   "source": [
    "## Parameter setup for k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69bd7e49-d2f2-47d1-8001-361c13968d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_demo_flag = False\n",
    "methods = ['down_sampling', 'stratified']\n",
    "method_selection = 'down_sampling'\n",
    "down_sampling_size = 5 # size for each train, val, and test set in each fold \n",
    "stratified_size = 1/10 # reduced ratio\n",
    "k = 5 # number of folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58d05c-97f8-4595-b5b4-1412945f674d",
   "metadata": {},
   "source": [
    "## Reducing data size for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9edd01-9b1e-4852-97c6-9cbd606e6825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size\n",
      "Whole:  14645\n"
     ]
    }
   ],
   "source": [
    "print(\"data size\")\n",
    "print(\"Whole: \", len(name_to_num))\n",
    "if quick_demo_flag == True:\n",
    "    if method_selection == 'down_sampling':\n",
    "        # Downsampling method\n",
    "        grouped = defaultdict(list)\n",
    "        for name, num in zip(name_to_num[:,0],name_to_num[:,1]):\n",
    "            grouped[num].append(name)\n",
    "    \n",
    "        min_size = min(len(names) for names in grouped.values())\n",
    "        accept_min = np.floor(min_size/(3*k)) # \n",
    "    \n",
    "        if (down_sampling_size > accept_min):\n",
    "            print(\"down_sampling_size is bigger than accpetable size. Some classes cannot be distributed to train/val/test sets.\")\n",
    "            down_sampling_size = accept_min\n",
    "            print(\"down_sampling_size is set to the minimun: \".format(down_sampling_size))\n",
    "            \n",
    "        random.seed(42)\n",
    "        \n",
    "        reduced_dataset_name = []\n",
    "        reduced_dataset_num = []\n",
    "        for num, names in grouped.items():\n",
    "            reduced_dataset_name.extend(random.sample(names,down_sampling_size*3*k))\n",
    "            reduced_dataset_num.extend([num]*down_sampling_size*3*k)\n",
    "    \n",
    "        final_name_to_num = np.array(list(zip(reduced_dataset_name,reduced_dataset_num)))\n",
    "\n",
    "    elif method_selection == 'stratified':\n",
    "        _, name_reduced_data, _, num_reduced_data = train_test_split(name_to_num[:,0], \n",
    "                                                                    name_to_num[:,1], \n",
    "                                                                    stratify=name_to_num[:,1],\n",
    "                                                                    test_size=stratified_size,\n",
    "                                                                    random_state=43)\n",
    "        final_name_to_num = np.array(list(zip(name_reduced_data,num_reduced_data)))\n",
    "\n",
    "    print(\"Reduced : \", len(final_name_to_num))\n",
    "  \n",
    "else:\n",
    "    final_name_to_num = name_to_num.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c66da-d58b-43c0-92cd-ff8843110459",
   "metadata": {},
   "source": [
    "### plot classification imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c922e205-eda0-497d-a1c9-3be06782523d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot for whole data\n",
    "def plot_class_dist(final_name_to_num, num_train, num_val, num_test, num_to_label, fold_count, save_dir):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    num_list = {\n",
    "        \"Whole\":final_name_to_num[:,1],\n",
    "        \"Train\":num_train,\n",
    "        \"Val\":num_val,\n",
    "        \"Test\":num_test\n",
    "    }\n",
    "    \n",
    "    l = len(num_list)\n",
    "    fig, ax= plt.subplots(2,2, figsize=(18, 10))\n",
    "    \n",
    "    \n",
    "    for i, (set_type, num) in enumerate(num_list.items()):\n",
    "        dataset_count = Counter([num_to_label[single_num] for single_num in num])\n",
    "        dataset_count = sorted(dataset_count.items(), key=lambda item: item[1],reverse=True)\n",
    "        class_names, count_values = zip(*dataset_count)\n",
    "\n",
    "        print(class_names)\n",
    "    \n",
    "        x = np.floor(i/2).astype(int)\n",
    "        y = i%2\n",
    "    \n",
    "        b_text = 20\n",
    "        m_text = 20\n",
    "        s_text = 5\n",
    "        \n",
    "        ax[x][y].bar(class_names, count_values)\n",
    "        ax[x][y].set_title('{:s} Data on Fold {}'.format(set_type, fold_count), fontsize=b_text, fontweight='bold')\n",
    "        ax[x][y].set_xlabel('Class Name', fontsize=m_text)\n",
    "        ax[x][y].set_ylabel('Data Size', fontsize=m_text)\n",
    "        ax[x][y].xaxis.set_tick_params(rotation=90)\n",
    "    \n",
    "    \n",
    "        max_count = max(count_values)\n",
    "    \n",
    "        n = int(np.floor(np.log10(max_count)))\n",
    "        step = 10**n\n",
    "    \n",
    "        ax[x][y].yaxis.set_major_locator(ticker.MultipleLocator(step))\n",
    "        ax[x][y].set_xticklabels(ax[x][y].get_xticklabels(), fontsize=s_text)\n",
    "        ax[x][y].set_yticklabels(ax[x][y].get_yticklabels(), fontsize=m_text)\n",
    "    \n",
    "        # y_ticks = list(ax[x][y].get_yticks())\n",
    "        # max_count_float = float(max_count)\n",
    "        \n",
    "        # if not any(np.isclose(tick, max_count_float) for tick in y_ticks):\n",
    "        #     y_ticks.append(max_count_float)\n",
    "        #     y_ticks = sorted(y_ticks)\n",
    "            \n",
    "    \n",
    "        # if max_count not in y_ticks:\n",
    "        #     y_ticks.append(max_count)\n",
    "        #     y_ticks = sorted(y_ticks)\n",
    "        \n",
    "        # ax[x][y].set_yticks(y_ticks)\n",
    "        # ax[x][y].set_ylim(bottom =0)\n",
    "    \n",
    "        # labels = [str(int(tick)) if tick.is_integer() else f\"{tick:.1f}\" for tick in y_ticks]\n",
    "        # ax[x][y].set_yticklabels(labels, fontsize=m_text)\n",
    "        \n",
    "    \n",
    "        print(\"Number of Classes for {} Data: {}\".format(set_type, len(class_names) ))\n",
    "    \n",
    "    fig.tight_layout(pad=3.0)\n",
    "    fig.savefig('{}/class_dist_fold_{}.png'.format(save_dir, fold_count))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550531f-1e7d-4eb1-a609-53a77235512b",
   "metadata": {},
   "source": [
    "## YOLO training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13976f7d-bf74-4a5a-a1e5-6ee96cc5e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_classify(fold_count, save_dir):\n",
    "    model = YOLO(\"yolov8n-cls.pt\")\n",
    "    \n",
    "    # Train model\n",
    "    train_results = model.train(\n",
    "        data=os.path.join(os.getcwd(), \"IP102/dataset\"),\n",
    "        epochs=1,\n",
    "        imgsz=640,\n",
    "        device=\"cpu\")\n",
    "\n",
    "    \n",
    "    # Validate\n",
    "    metrics = model.val()\n",
    "    \n",
    "    # Path to test dataset\n",
    "    test_dir = os.path.join(os.getcwd(), \"IP102/dataset/test\")\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # Get class mapping\n",
    "    class_names = model.names\n",
    "    \n",
    "    # Loop through test set\n",
    "    for class_name in os.listdir(test_dir):\n",
    "        class_path = os.path.join(test_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "    \n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            results = model.predict(image_path, verbose=False)\n",
    "            pred_idx = results[0].probs.top1\n",
    "            pred_name = class_names[pred_idx]\n",
    "            y_true.append(class_name)\n",
    "            y_pred.append(pred_name)\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"\\nEvaluation on Test Set:\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "    fold_evaluation = {\"accuracy\": acc,\"precison\":precision, \"recall\": recall, \"f1-score\":f1}\n",
    "    keys = fold_evaluation.keys()\n",
    "    rows = list(fold_evaluation.values())\n",
    "    \n",
    "    with open(\"{}/evaluation_fold_{}.csv\".format(save_dir,fold_count), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(keys)\n",
    "        writer.writerows([rows])\n",
    "\n",
    "\n",
    "    with open(\"{}/yolov8_config.json\".format(save_dir), \"w\") as f:\n",
    "        json.dump(model.overrides, f, indent=4)\n",
    "\n",
    "    true_pred = {\"true\":y_true, \"pred\":y_pred}\n",
    "    return true_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46e771-ae65-4532-864c-7fa7ab428c67",
   "metadata": {},
   "source": [
    "## 5-fold cross validation by StratifiedKFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73b79c5a-5650-42a7-b988-bb22ae072a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-30 16:20:40.255033\n",
      "['23' '68' '102' ... '102' '68' '102']\n",
      "('Cicadellidae', 'Lycorma delicatula', 'blister beetle', 'corn borer')\n",
      "Number of Classes for Whole Data: 4\n",
      "('Cicadellidae', 'Lycorma delicatula', 'blister beetle', 'corn borer')\n",
      "Number of Classes for Train Data: 4\n",
      "('Cicadellidae', 'Lycorma delicatula', 'blister beetle', 'corn borer')\n",
      "Number of Classes for Val Data: 4\n",
      "('Cicadellidae', 'Lycorma delicatula', 'blister beetle', 'corn borer')\n",
      "Number of Classes for Test Data: 4\n",
      "New https://pypi.org/project/ultralytics/8.3.146 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.134 🚀 Python-3.12.10 torch-2.2.2 CPU (Intel Core(TM) i9-9880H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/ikutatouma/Desktop/PBL5/project/IP102/dataset, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train36, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/ikutatouma/Desktop/PBL5/project/PBL5/runs/classify/train36, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/train... found 8787 images in 4 classes ✅ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/val... found 2929 images in 4 classes ✅ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/test... found 2929 images in 4 classes ✅ \n",
      "Overriding model.yaml nc=1000 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,443,412 parameters, 1,443,412 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 70.1±43.4 MB/s, size: 32.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/train... 87\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 52.5±38.4 MB/s, size: 24.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/val... 2929 i\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/ikutatouma/Desktop/PBL5/project/IP102/dataset/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/ikutatouma/Desktop/PBL5/project/PBL5/runs/classify/train36\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/550 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m move_img(train_val_test_pack)\n\u001b[32m     32\u001b[39m plot_class_dist(final_name_to_num, num_train, num_val, num_test, num_to_label, fold_counter, save_dir)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m y_true_pred_dic = \u001b[43myolo_classify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold_counter\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m all_y_true_pred[\u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m].extend(y_true_pred_dic[\u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     35\u001b[39m all_y_true_pred[\u001b[33m\"\u001b[39m\u001b[33mpred\u001b[39m\u001b[33m\"\u001b[39m].extend(y_true_pred_dic[\u001b[33m\"\u001b[39m\u001b[33mpred\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36myolo_classify\u001b[39m\u001b[34m(fold_count, save_dir)\u001b[39m\n\u001b[32m      2\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolov8n-cls.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIP102/dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m     13\u001b[39m metrics = model.val()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PBL5/project/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:793\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    792\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PBL5/project/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:211\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    208\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PBL5/project/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:399\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    394\u001b[39m     \u001b[38;5;28mself\u001b[39m.tloss = (\n\u001b[32m    395\u001b[39m         (\u001b[38;5;28mself\u001b[39m.tloss * i + \u001b[38;5;28mself\u001b[39m.loss_items) / (i + \u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss_items\n\u001b[32m    396\u001b[39m     )\n\u001b[32m    398\u001b[39m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PBL5/project/.venv/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    514\u001b[39m         Tensor.backward,\n\u001b[32m    515\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m         inputs=inputs,\n\u001b[32m    521\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/PBL5/project/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    261\u001b[39m     retain_graph = create_graph\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# train-val-test : 6-2-2\n",
    "move_back_img()\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "fold_counter = 0;\n",
    "\n",
    "all_y_true_pred = {\"true\":[], \"pred\":[]}\n",
    "\n",
    "time = str(datetime.datetime.today())\n",
    "save_dir = \"result/{}\".format(time)\n",
    "os.mkdir(save_dir)\n",
    "print(time)\n",
    "for train_index, test_index in skf.split(final_name_to_num[:,0], final_name_to_num[:,1].astype(int)):\n",
    "    fold_counter+=1\n",
    "    test_dataset = np.array([final_name_to_num[i] for i in test_index])\n",
    "    name_test, num_test = test_dataset[:,0], test_dataset[:,1]\n",
    "    \n",
    "    train_dataset = np.array([final_name_to_num[i] for i in train_index])\n",
    "    name_train, name_val, num_train, num_val = train_test_split(train_dataset[:,0], \n",
    "                                                                    train_dataset[:,1], \n",
    "                                                                    stratify=train_dataset[:,1],\n",
    "                                                                    test_size=0.25,\n",
    "                                                                    random_state=43)\n",
    "    train_val_test_pack = {\n",
    "        \"train\": {\"name\":name_train,\"num\":num_train},\n",
    "        \"val\":{\"name\":name_val,\"num\":num_val},\n",
    "        \"test\":{\"name\":name_test,\"num\":num_test}\n",
    "    }\n",
    "    \n",
    "    print(train_val_test_pack[\"train\"][\"num\"])\n",
    "\n",
    "    move_img(train_val_test_pack)\n",
    "    plot_class_dist(final_name_to_num, num_train, num_val, num_test, num_to_label, fold_counter, save_dir)\n",
    "    y_true_pred_dic = yolo_classify(fold_counter,save_dir)\n",
    "    all_y_true_pred[\"true\"].extend(y_true_pred_dic[\"true\"])\n",
    "    all_y_true_pred[\"pred\"].extend(y_true_pred_dic[\"pred\"])\n",
    "    move_back_img()\n",
    "\n",
    "\n",
    "acc = accuracy_score(all_y_true_pred[\"true\"], all_y_true_pred[\"pred\"])\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_y_true_pred[\"true\"], all_y_true_pred[\"pred\"], average='macro')\n",
    "\n",
    "print(\"\\nEvaluation on total {} folds:\".format(k))\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "total_evaluation = {\"accuracy\": acc, \"precison\":precision, \"recall\": recall, \"f1-score\":f1}\n",
    "\n",
    "keys = all_y_true_pred.keys()\n",
    "rows = zip(*all_y_true_pred.values())\n",
    "\n",
    "with open(\"{}/true_pred.csv\".format(save_dir), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keys)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "keys = total_evaluation.keys()\n",
    "rows = list(total_evaluation.values())\n",
    "\n",
    "with open(\"{}/total_evaluation.csv\".format(save_dir), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keys)\n",
    "    writer.writerows([rows])\n",
    "\n",
    "all_y_true_pred[\"true\"] = np.array(all_y_true_pred[\"true\"]).flatten()\n",
    "all_y_true_pred[\"pred\"] = np.array(all_y_true_pred[\"pred\"]).flatten()\n",
    "\n",
    "labels = list(num_to_label.values())\n",
    "\n",
    "cm = confusion_matrix(all_y_true_pred[\"true\"], all_y_true_pred[\"pred\"], labels=labels)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, xticklabels=labels, yticklabels=labels, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"{}/Confusion Matrix.png\".format(save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429fee5-eae6-4f19-b38c-cc634fdc1041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
